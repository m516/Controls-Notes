<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">=.1=</td>
<td style="text-align: left;">=</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">=.4=</td>
<td style="text-align: left;">=</td>
</tr>
</tbody>
</table>
<p><br />
<br />
</p>
<p><span class="math inline"><em>x</em></span> &amp;</p>
<ul>
<li><p>state vector (state space) (<a href="https://en.wikipedia.org/wiki/State_space">W</a>)<br />
Type: <span class="math inline">ℝ<sup><em>n</em></sup></span></p></li>
</ul>
<p><br />
</p>
<p><span class="math inline"><em>H</em></span> &amp;</p>
<ul>
<li><p>Hamiltonian matrix</p></li>
<li><p>Hamiltonian (Hamiltonian mechanics) (<a href="https://en.wikipedia.org/wiki/State_space">W</a>)<br />
type: <span class="math inline">ℝ<sup><em>n</em></sup> → ℝ</span></p>
<ul>
<li><p>Assuming discrete time linear system: <br /><span class="math display"><em>H</em><sub><em>k</em></sub> = <em>L</em>(<em>x</em><sub><em>k</em></sub>, <em>u</em><sub><em>k</em></sub>, <em>k</em>) + <em>p</em><sub><em>k</em> + 1</sub><sup><em>T</em></sup><em>f</em>(<em>x</em><sub><em>k</em></sub>, <em>u</em><sub><em>k</em></sub>, <em>k</em>)</span><br /></p></li>
</ul></li>
</ul>
<p><br />
</p>
<p><span class="math inline">ℒ</span> &amp;</p>
<ul>
<li><p>the Lagrangian<br />
type: <span class="math inline">ℝ<sup><em>n</em></sup> → ℝ</span></p></li>
</ul>
<p><br />
</p>
<p><span class="math inline"><em>e</em><sub>#</sub></span> &amp;</p>
<ul>
<li><p>The #th unit vector<br />
<br /><span class="math display">$$\qquad e_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \\\vdots \\ 0 \end{pmatrix},
          \qquad e_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\\vdots \\ 0 \end{pmatrix},
          \qquad e_3 = \begin{pmatrix} 0 \\ 0 \\ 1 \\\vdots \\ 0 \end{pmatrix},
          \qquad \hdots$$</span><br /></p></li>
</ul>
<p><br />
</p>
<p><span class="math inline">∇</span> &amp;</p>
<p>The del operator, which represents one of many long but similar operators on a vector field <span class="math inline"><em>v</em> ∈ ℝ<sup><em>n</em></sup></span>.</p>
<ul>
<li><p><span class="math inline">∇<em>f</em></span>: Gradient of a function <span class="math inline"><em>f</em> : ℝ<sup><em>n</em></sup> → ℝ</span>, returning an <span class="math inline"><em>n</em></span>-dimensional vector. (<a href="https://en.wikipedia.org/wiki/Del">W</a>)<br />
This vector points in the direction of the greatest increase, and its magnitude is the slope.<br />
For example, a mountain climber could approximate the shape of a convex mountain as a function <span class="math inline"><em>f</em><sub><em>m</em><em>o</em><em>u</em><em>n</em><em>t</em><em>a</em><em>i</em><em>n</em></sub></span> that computes the altitude given some latitude and longitude (assuming a very small mountain very far from the poles). In other words, <span class="math inline"><em>f</em><sub><em>m</em><em>o</em><em>u</em><em>n</em><em>t</em><em>a</em><em>i</em><em>n</em></sub> : ℝ<sup>2</sup> → ℝ</span>. The climber could know which direction to climb to summit the peak: it’s the direction <span class="math inline">∇<em>f</em></span>, and the grade or slope of the mountain is <span class="math inline">|∇<em>f</em>|</span><br />
Note that if <span class="math inline"><em>n</em> = 1</span>, <span class="math inline">∇<em>f</em></span> is the standard derivative of <span class="math inline"><em>f</em></span>.<br />
Formally speaking: <br /><span class="math display">$$\nabla f = \displaystyle\sum_{i=1} ^{n} \frac{\partial f}{\partial x_i} e_i$$</span><br /></p></li>
<li><p><span class="math inline">∇ ⋅ <em>v⃗</em></span>: The divergence of a vector field <span class="math inline"><em>v⃗</em></span></p></li>
<li><p><span class="math inline">∇ × <em>v⃗</em></span>: The curl of a vector field <span class="math inline"><em>v⃗</em></span></p></li>
<li><p><span class="math inline"><em>Δ</em><em>f</em></span>: the Laplace operator on a function <span class="math inline"><em>f</em> : ℝ<sup><em>n</em></sup> → ℝ</span>, equivalent to the divergence of the gradient of <span class="math inline"><em>f</em></span>, i.e. <br /><span class="math display"><em>δ</em><em>f</em> = ∇<sup>2</sup><em>f</em> = ∇ ⋅ ∇<em>f</em></span><br /></p></li>
</ul>
<p><br />
</p>
<p><span class="math inline"><em>J</em></span> &amp;</p>
<ul>
<li><p>Cost to go function<br />
type: <span class="math inline">ℝ<sup><em>n</em></sup> → ℝ</span></p></li>
</ul>
<p><br />
</p>
<p><span class="math inline"><em>p</em></span> &amp;</p>
<ul>
<li><p>Lagrange multiplier (<a href="https://en.wikipedia.org/wiki/Lagrange_multiplier">W</a>)</p></li>
</ul>
<p><br />
</p>
<p><span class="math inline"> &lt; &gt;</span> &amp;</p>
<ul>
<li><p>Lie bracket notation (<a href="https://en.wikipedia.org/wiki/Lie_bracket_of_vector_fields">W</a>)<br />
<span class="math inline"> &lt; <em>a</em>, <em>b</em> &gt;  = <em>b</em><sup><em>T</em></sup><em>a</em></span></p></li>
</ul>
<p><br />
</p>
<p>norm &amp;</p>
<ul>
<li><p>Vector norm (TODO)</p></li>
<li><p>Matrix norm (TODO)</p></li>
<li><p>Functional norm (TODO)</p></li>
</ul>
<p><br />
</p>
<p><br />
<br />
</p>
<p>Lipschitz Continuity<br />
<a href="https://en.wikipedia.org/wiki/Lipschitz_continuity">W</a>, <a href="https://math.berkeley.edu/~mgu/MA128ASpring2017/MA128ALectureWeek9.pdf">UC Berkley</a> &amp;</p>
<p>Lipschitz continuous functions are continuous and differentiable almost anywhere in a domain.<br />
<br />
Given a domain <span class="math inline"><em>D</em></span> and a function <span class="math inline"><em>f</em> : <em>D</em> → ℝ, <em>D</em> ∈ ℝ<sup><em>n</em></sup></span>,<br />
<span class="math inline"><em>f</em></span> is Lipschitz continuous if <span class="math inline">∃<em>L</em> &gt; 0</span> such that <span class="math inline">|<em>f</em>(<em>x</em>) − <em>f</em>(<em>y</em>)| &lt; <em>L</em>||(<em>x</em> − <em>y</em>)||∀<em>x</em>, <em>y</em> ∈ <em>D</em></span></p>
<p><br />
</p>
<p>Hessian<br />
<a href="https://en.wikipedia.org/wiki/Hessian_matrix">W</a>, <a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/quadratic-approximations/a/the-hessian">Kahn Academy</a>, <a href="https://mathworld.wolfram.com/Hessian.html">Wolfram</a> &amp;</p>
<ul>
<li><p>A <span class="math inline">2<em>n</em></span> x <span class="math inline">2<em>n</em></span> matrix of all 2nd order partial derivatives of some function <span class="math inline"><em>f</em> : ℝ<sup><em>n</em></sup> → ℝ</span></p></li>
<li><p>The determinant of a Hessian matrix</p></li>
</ul>
<p><br />
</p>
<p>definite<br />
<a href="https://en.wikipedia.org/wiki/Positive-definite_function">W</a> &amp;</p>
<p><em>Warning: this definition does not appear to be common outside of controls</em><br />
Given a real-valued, continuously differentiable function <span class="math inline"><em>V</em>(<em>x</em>) : ℝ → ℝ</span><br />
<span class="math inline"><em>V</em>(<em>x</em>)</span> can be classified as</p>
<ul>
<li><p><strong>(globally) positive semidefinite</strong> if <br /><span class="math display"><em>V</em>(<em>x</em>) ≥ 0   ∀<em>x</em> ∈ ℝ</span><br /></p>
<p><em>(<span class="math inline"><em>v</em></span> is greater than or equal to 0 regardless of <span class="math inline"><em>x</em></span>)</em></p></li>
<li><p><strong>(globally) positive definite</strong> if positive semidefinite AND <br /><span class="math display"><em>V</em>(<em>x</em>) = 0 ⇔ <em>x</em> = 0</span><br /></p>
<p><em>(<span class="math inline"><em>V</em>(<em>x</em>)</span> is zero if and only if <span class="math inline"><em>x</em></span> is zero)</em></p></li>
<li><p><strong>(globally) negative semidefinite</strong> if <br /><span class="math display"><em>V</em>(<em>x</em>) ≤ 0   ∀<em>x</em> ∈ ℝ</span><br /></p>
<p><em>(<span class="math inline"><em>v</em></span> is less than or equal to 0 regardless of <span class="math inline"><em>x</em></span>)</em></p></li>
<li><p><strong>(globally) negative definite</strong> if negative semidefinite AND <br /><span class="math display"><em>V</em>(<em>x</em>) = 0 ⇔ <em>x</em> = 0</span><br /></p>
<p><em>(<span class="math inline"><em>V</em>(<em>x</em>)</span> is zero if and only if <span class="math inline"><em>x</em></span> is zero)</em></p></li>
<li><p><strong>locally positive definite (l.p.d)</strong> if <br /><span class="math display"><em>V</em>(<em>x</em>) ≥ 0   ∀<em>x</em> ∈ <em>N</em></span><br /> where <span class="math inline"><em>N</em></span> is a small open neighborhood containing <span class="math inline">$\Vec{0}$</span></p>
<p><em>(<span class="math inline"><em>v</em></span> is greater than or equal to 0 regardless of <span class="math inline"><em>x</em></span> in some small open neighborhood <span class="math inline"><em>N</em></span> that contains the zero vector)</em></p>
<p><strong>AND</strong></p>
<p><br /><span class="math display"><em>V</em>(<em>x</em>) = 0 ⇔ <em>x</em> = 0</span><br /></p>
<p><em>(<span class="math inline"><em>V</em>(<em>x</em>)</span> is zero if and only if <span class="math inline"><em>x</em></span> is zero)</em></p>
<p>Note that the criteria for a function to be locally positive definite are similar, but more relaxed than, those for globally positive definite functions.</p></li>
<li><p><strong>positive definite on some domain <span class="math inline"><em>D</em> ∈ ℝ<sup><em>n</em></sup></span></strong> if<br />
we only care if the conditions for positive definite functions hold for all <span class="math inline"><em>x</em></span> in <span class="math inline"><em>D</em></span>.</p></li>
</ul>
<p><br />
</p>
<p>Stability &amp;</p>
<ul>
<li><p>(Lyapunov) stability (TODO)</p></li>
<li><p>Asymptotic stability (TODO)</p></li>
<li><p>Exponential stability (TODO)</p></li>
<li><p>Uniform stability (TODO)</p></li>
<li><p>Global stability (TODO)</p></li>
<li><p>L-stability (TODO)</p></li>
<li><p>I/O L-stability (TODO)</p></li>
<li><p>Small-signal I/O L-stability (TODO)</p></li>
<li><p>Small-signal finite-gain L-stability (TODO)</p></li>
</ul>
<p><br />
</p>
<p>Class K function &amp;</p>
<ul>
<li><p>(TODO)</p></li>
</ul>
<p><br />
</p>
<p>Radially Unbounded function &amp;</p>
<ul>
<li><p>(TODO)</p></li>
</ul>
<p><br />
</p>
<p><span class="math inline">sup </span> (supremum) &amp;</p>
<p>Like a maximum of a functions, but includes limits that aren’t necessarily a part of the domain of the function. (TODO)</p>
<p><br />
</p>
<p><br />
<br />
</p>
