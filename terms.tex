
\boldentry{Terms}




\entry{  
    Classes of Systems
}{
    Given a dynamic system
    
    \begin{itemize}
        \setlength\itemsep{2em}
        \item \textbf{Dynamic system}
        \[\dot{x} = f(x, u, t)\]
        \item \textbf{Time-invariant system} is a dynamic system
        \[\dot{x} = f(x, u)\]
        \item \textbf{Autonomous system} is a dynamic system
        \[\dot{x} = f(x, t)\]
        \item \textbf{Linear system}
        (\href{https://en.wikipedia.org/wiki/Linear_system}{W})
        is a dynamic system
        \[\dot{x} = f(x, u, t) = A(t) x + B(t) u\]
        \item \textbf{Linear time-invariant system} is a linear system and a time-invariant system
        \[\dot{x} = f(x, u) = A x + B u\]
    \end{itemize}
}



\entry{  
    Lipschitz Continuity
    (\href{https://en.wikipedia.org/wiki/Lipschitz_continuity}{W},)
    (\href{https://math.berkeley.edu/~mgu/MA128ASpring2017/MA128ALectureWeek9.pdf}{UC Berkley})
}{
    Lipschitz continuous functions are continuous and differentiable almost anywhere in a domain. \\\\
    Given a domain $D$ and a function $f: D \rightarrow \mathbb{R}, D \in \mathbb{R}^n$, \\
    $f$ is Lipschitz continuous if $\exists L>0$ such that $|f(x) - f(y)| < L ||(x-y)|| \forall x,y \in D$
}



\entry{  
    Hessian
    (\href{https://en.wikipedia.org/wiki/Hessian_matrix}{W}),
    (\href{https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/quadratic-approximations/a/the-hessian}{Kahn Academy}),
    (\href{https://mathworld.wolfram.com/Hessian.html}{Wolfram})
}{
\begin{itemize}
    \item A $n$ x $n$ matrix of all 2nd order partial derivatives of some function $f : \mathbb{R}^n \rightarrow \mathbb{R}$
    
    \begin{equation}
        H f(\Vec{x}) = f"(\Vec{x}) = 
        \left(
        \begin{matrix} 
                \frac{\partial^2 f}{\partial x_1 \partial x_1} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \frac{\partial^2 f}{\partial x_1 \partial x_3} &  \dots  & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
                \frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2 \partial x_2} & \frac{\partial^2 f}{\partial x_2 \partial x_3} &  \dots  & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
                \frac{\partial^2 f}{\partial x_3 \partial x_1} & \frac{\partial^2 f}{\partial x_3 \partial x_2} & \frac{\partial^2 f}{\partial x_3 \partial x_3} &  \dots  & \frac{\partial^2 f}{\partial x_3 \partial x_n} \\
                \vdots & \vdots & \vdots & \ddots & \vdots \\
                \frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \frac{\partial^2 f}{\partial x_n \partial x_3} &  \dots  & \frac{\partial^2 f}{\partial x_n \partial x_n} \\
        \end{matrix} 
        \right)
    \end{equation}
    \item The determinant of a Hessian matrix
\end{itemize} 
}



\entry{  
    definite
    (\href{https://en.wikipedia.org/wiki/Positive-definite_function}{W})
}{
\emph{Warning: this definition does not appear to be common outside of controls}\\

Given a real-valued, continuously differentiable function $V(x) : \mathbb{R} \rightarrow \mathbb{R}$ \\
$V(x)$ can be classified as
\begin{itemize}
    \setlength\itemsep{2em}
    \item 
        \textbf{(globally) positive semidefinite} if 
        \[
            V(x) \geq 0 \qquad \forall x \in \mathbb{R}
        \]
        \begin{center}
            \textit{($v$ is greater than or equal to 0 regardless of $x$)}
        \end{center}
    
    \item 
        \textbf{(globally) positive definite} if positive semidefinite AND
        \[
            V(x) = 0 \iff x = 0
        \]
        \begin{center}
            \textit{($V(x)$ is zero if and only if $x$ is zero)}
        \end{center}
        
    \item 
        \textbf{(globally) negative semidefinite} if 
        \[
            V(x) \leq 0 \qquad \forall x \in \mathbb{R}
        \]
        \begin{center}
            \textit{($v$ is less than or equal to 0 regardless of $x$)}
        \end{center}
    
    \item 
        \textbf{(globally) negative definite} if negative semidefinite AND
        \[
            V(x) = 0 \iff x = 0
        \]
        \begin{center}
            \textit{($V(x)$ is zero if and only if $x$ is zero)}
        \end{center}

        
    \item 
        \textbf{locally positive definite (l.p.d)} if 
        \[
            V(x) \geq 0 \qquad \forall x \in N
        \]
        where $N$ is a small open neighborhood containing $\Vec{0}$
        \begin{center}
            \textit{($v$ is greater than or equal to 0 regardless of $x$ in some small open neighborhood $N$ that contains the zero vector)}
        \end{center}
        \begin{center}
            \textbf{AND}
        \end{center}
        \[
            V(x) = 0 \iff x = 0
        \]
        \begin{center}
            \textit{($V(x)$ is zero if and only if $x$ is zero)}
        \end{center}

        Note that the criteria for a function to be locally positive definite are similar, but more relaxed than, those for globally positive definite functions.

        
    \item 
        \textbf{positive definite on some domain $D \in \mathbb{R}^n$} if \\
        we only care if the conditions for positive definite functions hold for all $x$ in $D$.
    
    
\end{itemize} 
} % end definite






\entry{  
    Stability 
    (\href{http://underactuated.mit.edu/lyapunov.html}{MIT})
}{
Given an autonomous system \[\dot{x} = f(x, t)\] and some open connected region $\mathcal{D}$ containing $\Vec{0}$\\

Stability is usually used to describe trajectories around the origin of a system.\\

\begin{itemize}
    \setlength\itemsep{2em}
    \item \textbf{Stability}\\
    The equilibrium point $x=0$ is stable if $\forall \epsilon>0$, $\exists \delta(\epsilon)>0$ such that $\norm{x(0)}<\delta \implies \norm{x(t)}<\epsilon$

    \begin{itemize}
        \item \textbf{In the sense of Lyapunov}\\
        If there exists a scalar, continuously-differentiable function $V(x)$ such that
        \[V(x)>0 \quad \forall x \in \mathcal{D}\setminus\left\{\Vec{0}\right\},\qquad V(\Vec{0})=0\]
        \begin{center}
            \textit{($V(x)$ is a locally positive definite function)}
        \end{center}
        \begin{center}\textbf{AND}\end{center}
        \[\dot{V}(x)=\frac{\partial V}{\partial x} f(x) \leq 0 \quad \forall x \in \mathcal{D}\setminus\left\{\Vec{0}\right\},\qquad V(\Vec{0})=0\]
        \begin{center}
            \textit{($\dot{V}(x)$ is a locally negative semidefinite function)}
        \end{center}
        then the origin is stable in the sense of Lyapunov, and $V(x)$ is a Lyapunov function of $f(x)$.
    \end{itemize}
    
    
    \item \textbf{Instability}\\
    The equilibrium point $x=0$ is unstable if it is not stable
    
    
    \item \textbf{Asymptotic stability}\\
    The equilibrium point $x=0$ is asymptotically stable if it is stable and $\exists \delta_1$ such that $\norm{x(0)}<\delta_1 \implies \lim\limits_{t\rightarrow\infty}x(t)=0$

    \begin{itemize}
        \item \textbf{In the sense of Lyapunov}\\
        The origin is asymptotically stable in the sense of Lyapunov if stable AND
        \[\dot{V}(x)=\frac{\partial V}{\partial x} f(x) < 0 \quad \forall x \in \mathcal{D}\setminus\left\{\Vec{0}\right\}\]
        \begin{center}
            \textit{($\dot{V}(x)$ is a locally negative definite function)}
        \end{center}
    \end{itemize}
    
    \item \textbf{Exponential stability}\\  
    \begin{itemize}
        \item \textbf{In the sense of Lyapunov}\\
        The origin is exponentially stable in the sense of Lyapunov if stable AND
        \[\dot{V}(x)=\frac{\partial V}{\partial x} f(x) \leq -\alpha V(x) \quad \forall x \in \mathcal{D}\setminus\left\{\Vec{0}\right\}\]
    \end{itemize}
    
    \item \textbf{Uniform stability}\\
    The equilibrium point $x=0$ is uniformly stable if it is stable and, for each $epsilon>0$, there exists a $\delta(\epsilon)>0$, independent of $t_0$.
\end{itemize}
}
    
\entry{  
    Stability 
    (continued)
}{
\begin{itemize}
    
    \item \textbf{Global asymptotic stability}\\
    \begin{itemize}
        \item \textbf{In the sense of Lyapunov}\\
        If the origin is globally asymptotically stable in the sense of Lyapunov if is asymptotically stable and 
        \[\norm{x}\rightarrow\infty \implies V(x)\rightarrow\infty\]
        \begin{center}
            \textit{($V(x)$ is radially unbounded)}
        \end{center}
    \end{itemize}
    
    \item \textbf{L-stability}\\ (TODO)
    
    \item \textbf{I/O L-stability}\\ (TODO)
    
    \item \textbf{Finite-gain L-stability}\\ (TODO)
    
    \item \textbf{Small-signal I/O L-stability}\\ (TODO)
    
    \item \textbf{Small-signal finite-gain L-stability}\\ (TODO)
    
    
\end{itemize} 
}






\entry{  
    Class $\kappa$ function
}{
A continuous scalar function on $\mathbf{R}^+$ is 

\begin{itemize}
    \item \textbf{class $\kappa$} if it is:
    \begin{itemize}
        \item zero at zero
        \item strictly increasing
        \item continuous
    \end{itemize}
    
    \item \textbf{class $\kappa_\infty$} if it is:
    \begin{itemize}
        \item zero at zero
        \item strictly increasing
        \item continuous
        \item $\infty$ at $\infty$
    \end{itemize}
\end{itemize} 
}






\entry{  
    Radially Unbounded function
}{
A function $V(x)$ is radially unbounded if 
\[\norm{x}\rightarrow\infty \implies \norm{V(x)}\rightarrow\infty\]
}






\entry{  
    $\sup$ (supremum)
}{
    Like a maximum of a functions, but includes limits that aren't necessarily a part of the domain of the function.
    (TODO)
}





\entry{  
    Hurwitz
}{
\begin{itemize}
    \item \textbf{Hurwitz (polynomial)}: \\
        A polynomial whose roots that are all in the left-half plane. (In other words, the real part of every root is strictly negative)
    \item \textbf{Hurwitz (matrix)} (\href{https://en.wikipedia.org/wiki/Hurwitz_matrix}{W}): \\
        A square matrix whose characteristic polynomial is Hurwitz, meaning all eigenvalues are in the left-half plane. (In other words, the real part of every eigenvalue is strictly negative)
    \item \textbf{Routh-Hurwitz stability criterion} (\href{https://ieeexplore.ieee.org/document/165530}{IEEE}): \\
        TODO
\end{itemize} 

Any hyperbolic fixed point (or equilibrium point) of a continuous dynamical system is locally asymptotically stable if and only if the Jacobian of the dynamical system is Hurwitz stable at the fixed point.

A system is stable if its control matrix is a Hurwitz matrix. 

The negative real components of the eigenvalues of the matrix represent negative feedback. Similarly, a system is inherently unstable if any of the eigenvalues have positive real components, representing positive feedback. 
}





\entry{  
    Zero-state observable
}{
    A time-invariant system of the form
    \[ \begin{cases} 
          \dot{x} = f(x, u) \\
          y = h(x, u)
       \end{cases}
    \]
    
    is zero-state observable if
    
    \[ \begin{cases} 
          y \equiv 0 \\
          u \equiv 0
    \end{cases} \implies x \equiv 0
    \]

    In other words, when $u=0$, any nonzero state behavior will be observed at the output ($y\neq0$)
}






\entry{  
    Sets
}{
\begin{itemize}
    \item \textbf{Invariant Set} \\
    A set of vectors $M$ is invariant with respect to $\dot{x} = f(x)$ if
    \[
    x(0) \in M \implies x(t) \in M, \qquad \forall t \in \mathbb{R} 
    \]
    \begin{center}
        \emph{(if a solution belongs to M at some time instant, then it belongs to M for
all future and past time)}
    \end{center}
    
    \item \textbf{Positively Invariant Set} \\
    A set of vectors $M$ is positively invariant with respect to $\dot{x} = f(x)$ if
    \[
    x(0) \in M \implies x(t) \in M, \qquad \forall t \geq 0
    \]
    \begin{center}
        \textit{}{(if a solution belongs to M at some time instant, then it belongs to M for
all future time)}
    \end{center}

    \item \textbf{Open Set}\\
    A set $D\subset\mathbb{R}^n$ (\textit{$D$, which is a set of real vectors}) is an \textbf{open set} if 
    \[\forall x \subset D, \quad \exists \epsilon>0 \quad \text{ such that } \quad B\left(x, \epsilon\right) \subset D\]
    
    \begin{center}
        \textit{(for all vectors $x$ in the domain $D$, there exists a real scalar $\epsilon$ such that we can create a ball around $x$ with radius $\epsilon$, and that whole ball is in $D$)}
    \end{center}

    \item \textbf{Closed Set}\\
     A set $D\subset\mathbb{R}^n$ (\textit{$D$, which is a set of real vectors}) is a \textbf{closed set} if 
    \[\mathbb{R}^n \setminus D \quad \text{is an open set}\]
    \begin{center}
        \textit{(everywhere outside of $D$ is open)}
    \end{center}

    \item \textbf{Bounded Set}\\
    A set $D\subset\mathbb{R}^n$ (\textit{$D$, which is a set of real vectors}) is a \textbf{bounded set} if 
    \[\exists \epsilon>0 \quad \text{ such that } \quad D \subset B\left(0, \epsilon\right)\]
    
    \begin{center}
        \textit{($D$ fits in a ball with a finite, constant radius $\epsilon$)}
    \end{center}

    \item \textbf{Compact Set}\\
    A set $D\subset\mathbb{R}^n$ (\textit{$D$, which is a set of real vectors}) is a \textbf{compact set} if it is closed and bounded.
    
\end{itemize}
}







\entry{  
    Passivity
}{

For a system $y=h(u,t), \quad h:\mathbb{R}^m \times \left[0,\infty\right) \rightarrow \mathbb{R}^n$ \\
\textit{(output state $y$ (an $n$-dimensional vector) is a function of the input state $u$ (an $m$-dimensional vector) and time t)}

\begin{itemize}
    \item \textbf{Invariant Set} \\
    A set of vectors $M$ is invariant with respect to $\dot{x} = f(x)$ if
    \[
    x(0) \in M \implies x(t) \in M, \qquad \forall t \in \mathbb{R} 
    \]
    \begin{center}
        \emph{(if a solution belongs to M at some time instant, then it belongs to M for
all future and past time)}
    \end{center}
    
\end{itemize}
}







\entry{  
    Adjoint
}{

\begin{itemize}
    \item The \textbf{\{adjoint or Hermitian transpose\} of a matrix $A$} (\href{https://mathworld.wolfram.com/AdjointRepresentation.html}{Wolfram}) is its conjugate transpose, denoted as $A'$, $A^*$, $A^H$, or $A^\dagger$ i.e. 
    \[
    A^H=\overline{A}^T
    \]
    Interesting properties of ajoint matrices:
    \begin{itemize}
        \item $A^H=\overline{A}^T=\overline{A^T}$
        \item If a matrix is its own conjugate transpose, that matrix is called \textbf{self-adjoint} or \textbf{Hermetian}
        \item If $A$ is a real matrix, $A^H=A^T$
    \end{itemize}
    Warning: In some older literature, the "adjoint of a matrix" may mean the \textbf{adjunct matrix of a square matrix} (\href{https://en.wikipedia.org/wiki/Adjugate_matrix}{W})
    
    
    \item The \textbf{adjoint representation of a vector space} (\href{https://mathworld.wolfram.com/AdjointRepresentation.html}{Wolfram}) \\
    (TODO)
    
    \item The \textbf{adjoint equation} (\href{https://en.wikipedia.org/wiki/Adjoint_equation}{W}) \\
    (TODO)

    
    
\end{itemize}
}
